## 锁

### lock 和 latch

`latch` 一般称为闩锁（轻量级的锁），因为其要求锁定的时间必须非常短。`latch` 又可以分为 `mutex`（互斥量）和 `rwlock`（读写锁）。其目的是用来**保证并发线程操作临界资源的正确性，并且通常没有死锁检测的机制**。

`lock` 的对象是**事务**，用来锁定的是数据库中的对象，如表、页、行。并且一般 `lock` 的对象仅在事务 `commit` 或 `rollback` 后进行释放，是**有死锁机制**的。

|          | lock                                                        | latch                                                        |
| -------- | :---------------------------------------------------------- | :----------------------------------------------------------- |
| 对象     | 事务                                                        | 线程                                                         |
| 保护     | 数据库内容                                                  | 内存数据结构                                                 |
| 持续时间 | 整个事务过程                                                | 临界资源                                                     |
| 模式     | 行锁、表锁、意向锁                                          | 读写锁、互斥锁                                               |
| 死锁     | 通过 waits-for graph、time out 等机制进行死锁进行检测与处理 | 无死锁检测与处理机制。仅通过应用程加锁的顺序（lock leveling）保证无死锁的情况发生 |
| 存在于   | Lock Manager 的哈希表中                                     | 每个数据结构的对象中                                         |



### InnoDB 存储引擎中的锁

#### 锁的类型

InnoDB 存储引擎实现了如下两种标准的行级锁：

- 共享锁（S Lock），允许事务读一行数据。
- 排它锁（X Lock），允许事务删除或更新一行数据。

排它锁与共享锁的兼容性：

|       |   X    |   S    |
| :---: | :----: | :----: |
| **X** | 不兼容 | 不兼容 |
| **S** | 不兼容 |  兼容  |

> S 和 X 锁都是行锁，兼容是指对同一记录（row）锁的兼容性情况。

此外，InnoDB 存储引擎支持多粒度（granular）锁定，这中锁定**允许事务在行级上的锁和表锁同时存在**。为了支持多粒度锁定，InnoDB 存储引擎支持了一种额外的锁方式，称之为意向锁（ IX Intention Lock）。意向锁是将锁定的对象分为多个层次，意向锁是**表级别**的锁，它**在锁定细粒度的对象锁时，首先要对粗粒度的对象上锁**。

意向锁也分为两种：

- 意向共享锁（IS Lock），事务想要获得一张表中某几行的共享锁。
- 意向排它锁（IX Lock），事务想要获得一张表中某几行的排它锁。

由于 InnoDB 存储引擎支持的是行级别的锁，因此意向锁其实不会阻塞除全表扫以外的任何请求。

InnoDB 存储引擎中锁的兼容性：

|        |   IS   |   IX   |   S    |   X    |
| :----: | :----: | :----: | :----: | :----: |
| **IS** |  兼容  |  兼容  |  兼容  | 不兼容 |
| **IX** |  兼容  |  兼容  | 不兼容 | 不兼容 |
| **S**  |  兼容  | 不兼容 |  兼容  | 不兼容 |
| **X**  | 不兼容 | 不兼容 | 不兼容 | 不兼容 |



#### 一致性非锁定读

一致性的非锁定读（consistent nonlocking read）是指 InnoDB 存储引擎通过行多版本控制（multi versioning）的方式来读取当前执行时间数据库中行的数据。如果读取的行正在执行 `DELETE` 或 `UPDATE` 操作，这时读取操作不会因此去等待行上锁的释放。相反地，InnoDB 存储引擎会去读取行的一个**快照数据**。

快照数据是指该行的之前版本的数据，该实现是通过 undo 段来完成。而 undo 是用来在事务中回滚数据，因此读取快照数据是不需要上锁的。

在不同的事务隔离级别下，非锁定读对于快照数据的定义也不同：

- `READCOMMITED` ：非一致性读总是读取被锁定行的最新一份数据。

- `REPEATABLE READ` ：非一致性读总是读取事务开始时的行数据版本。

#### 一致性锁定读

在默认情况下，InnoDB 存储引擎的 `SELECT` 操作使用一致性非锁定读。如果要显示地对数据读取操作进行加锁以保证数据逻辑的一致性，就需要使用一致性的锁定读。

 

InnoDB 存储引擎对于 SELECT 语句支持两种一致性的锁定读（locking read）操作：

- `SELECT ... FOR  UPDATE`
- `SELECT ... LOCK IN SHARE MODE`

`SELECT ... FOR  UPDATE` 对读取的行记录加一个 X 锁，其他事务不能对已锁定的行加上任何锁。

`SELECT ... LOCK IN SHARE MODE` 对读取的行记录加一个 S 锁，其他事务可以向被锁定的行加 S 锁，但是如果加 X 锁，则会被阻塞。



#### 自增长与锁

在 InnoDB 存储引擎中，对每个自增长值得表都有一个自增长计数器（auto-increment counter）。当对含有自增长的计数器的表进行插入操作时，这个计数器会被初始化，执行如下语句来得到计数器的值：

```mysql
select max(auto_inc_col) from t for update
```

插入操作会依据这个自增长计数器值加 1  赋予自增长列。这种实现方式叫做 **AUTO-INC Locking**。特点：

- 这种锁其实是一种特殊的**表锁机制**，锁是在完成对自增长值插入的 SQL 语句后立即释放，而不是事务完成后释放。
- 对于自增长值的列的**并发插入性能较差**。事务必须等待前一个插入的完成（虽然不用等待事务的完成）
- 对于 `INSERT ... SELECT` 的大数据量的插入会影响插入性能，因为另外一个事务的插入会被阻塞。

从 MySQL 5.1.22 版本开始，提供了一种轻量级互斥量的自增长实现机制。

- 提供了一个参数 `innodb_autoinc_lock_mode` 来控制自增长的模式，默认值为 2 。
  - 0：通过表锁 `AUTO-INC Locking` 方式实现。
  - 1：对于 `simple inserts` 会用互斥量（mutex）去对内存中的计数器进行累加。对于 `bulk inserts` ，采用 `AUTO-INC Locking` 。
  - 2：对于 `insert-like` 自增长的值都是通过互斥量。这是性能最高的方式。但也有一定的问题，由于并发插入的存在，自增长值可能不是连续的。最重要的是，基于 `Statement-Base Replication` 会出现问题，使用 `row-base replication` 才能保证最大的并发性能及 replication 主从数据的一致。

>  自增长的分类：
>
> | 插入类型             | 说明                                                         |
> | -------------------- | ------------------------------------------------------------ |
> | `insert-like`        | 指所有的插入语句                                             |
> | `simple inserts`     | 指能在插入前就确定插入行数的语句，不包括 `INSERT .. ON DUPLICATE KEY  UPDATE`这类语句 |
> | `bulk inserts`       | 指在插入前不能确定插入行数的语句                             |
> | `mixed-mode inserts` | 指插入中有一部分的值是自增长的，有一部分是确定的。如：`INSERT INTO t(c1,c2) VALUES (1,'a'),(NULL,'b');`；也可以指 `INSERT .. ON DUPLICATE KEY  UPDATE`这类语句 |



### 锁的算法

#### 行锁的 3  种算法

InnoDB 存储引擎有 3 中行锁的算法：

- Record Lock：单个行记录上的锁
- Gap Lock：间隙锁，锁定一个范围，但不包含记录本身。
- Next-Key Lock：Gap Lock + Record Lock ，锁定一个范围，并且锁定记录本身。（解决 `Phantom Problem`）

当查询的索引含有唯一属性时，InnoDB 存储引擎会对 Next-Key Lock 进行优化，将其降级为 Record Lock，即仅锁住索引本身，而不是范围。

Gap Lock 的作用是为了阻止多个事务将记录插入到同一个范围内，用户可以通过以下两种方式来显示地关闭 Gap Lock:

- 将事务的隔离级别设置为 READ COMMITED

- 将参数 innodb_locks_unsafe_for_binlog 设置为 1（MySQL 8.0.0 已经移除）

  > - `innodb_locks_unsafe_for_binlog`: Force InnoDB not to use next-key locking. Instead use only row-level locking. Removed in MySQL 8.0.0.



#### 解决 Phantom Problem

在默认的事务隔离级别下（Repeatable Read）下，InnoDB 存储引擎采用 Next-Key Locking 机制来避免 Phantom Problem （幻像问题）和 不可重复读问题。



## 事务

### 事务的实现

原子性、一致性、持久性通过数据库的 redo log 和 undo log 来完成。redo log 称为重做日志，用来保证事务的原子性和持久性。undo log 用来保证事务的一致性。

- redo 恢复提交事务修改的页操作，通常是物理日志，记录的的是页的物理修改操作。
- undo 回滚行记录到某个特定的版本，是逻辑日志，根据每行记录进行记录。

#### redo

重做日志用来实现事务的持久性，其由两部分组成：

- 内存中的重做日志缓冲（redo log buffer），其是易失的；
- 重做日志文件（redo log  file），其是持久的；

InnoDB 是事务的存储引擎，其通过 `Force Log at Commit` 机制实现事务的持久性，即当事务提交（COMMIT）时，必须先将该事务的所有日志写入到重做日志文件进行持久化，待事务的 COMMIT 操作完成才算完成。这里的日志由两部分组成，即 redo log 和 undo log。**redo log 用来保证事务的持久性，undo log 用来帮助事务回滚及 MVCC 的功能**。redo log 基本上都是顺序写的，在数据库运行时不需要对 redo log 的文件进行读取操作。而 undo log 是需要进行随机读写的。

为了确保每次日志都写入重做日志文件，在每次将重做日志缓冲写入重做日志文件后，InnoDB 存储引擎都需要调用一次 fsync 操作。

`innodb_flush_log_at_trx_commit` 用来控制重做日志刷新到磁盘的策略：

- 0 ：表示事务提交时不进行写入重做日志操作，这个操作仅在 master thread 中完成，而 master thread 中每 1 秒会进行一次重做日志文件的 fsync 操作。
- 1：表示事务提交时必须调用一次 fsync 操作。**（默认值）**
- 2：表示事务提交时将重做日志写入重做日志文件，但仅写入文件系统的缓存中，不进行 fsync 操作。 操作系统宕机时，会丢失未从文件系统缓存刷新到重做日志文件那部分的事务。

在 MySQL 数据库中还有一种二进制日志（binlog），其用来进行 POINT-IN-TIM（PIT）的恢复及主从复制（Replication）环境的建立。

二进制日志和重做日志的区别：

- 产生层次不同。重做日志是在 InnoDB 存储引擎层产生，而二进制日志是在 MySQL 数据库的上层产生的，并且二进制日志不仅仅针对于 InnoDB 存储引擎，MySQL 数据库中的任何存储引擎对于数据库的更改都会产生二进制日志。
- 记录的内容形式不同。二进制日志是一种逻辑日志，其记录的是对应的 SQL 语句；重做日志是物理格式日志，其记录的是对于每个页的修改。
- 写入磁盘的时间点不同。二进制日志只在事务提交完成后进行一次写入；重做日志在事务进行中不断地被写入，这表现为日志并不是随事务提交的顺序进行写入的。

![二进制日志与重做日志的写入的时间点不同](https://cdn.jsdelivr.net/gh/YangZhiqiang98/ImageBed/20211026211729.png)

从上图可以看出，二进制日志仅在事务提交时记录，并且对于每一个事务，仅包含对应事务的一个日志。对于重做日志，每个事务都对应多个日志条目，并且事务的重做日志写入是并发的，并非在事务提交时写入。`*Tn` 表示的是事务提交时的日志。

在 InnoDB 存储引擎中， 重做日志都是以 512 字节存储的，即一个块的大小，因此日志的写入可以保证原子性，不需要 doublewrite 技术。若一个页中产生的重做日志数量大于 512 字节，那么需要分割为多个重做日志块进行存储。



#### undo

undo 存放在数据库内部的一个特殊段（undo segment）。undo 段位于共享表空间内。

undo 是逻辑日志，用于将数据库**逻辑地**恢复到原来的样子。所有的修改都被逻辑地取消了，但是数据结构和页本身在回滚之后可能不大相同（并发访问的存在，不能将一个页回滚到事务开始的样子，这样会影响正在进行的工作）。

undo 的作用：

- 回滚：回滚时，做的是之前相反的操作。对于 INSERT，执行一个 DELETE；对于 DELETE，存储引擎执行一个相反的 INSERT；对于 UPDATE ，执行一个相反的 UPDATE 。 
- MVCC：通过 undo 读取之前的行版本信息，以此实现非锁定读。





