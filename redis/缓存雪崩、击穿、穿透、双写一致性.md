#### 缓存穿透

缓存穿透是指查询一个一定**不存在的数据**。由于缓存不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个**不存在的数据每次请求都要到数据库去查询**，进而给数据库带来压力。

> 通俗点说，读请求访问时，缓存和数据库都没有某个值，这样就会导致每次对这个值的查询请求都会穿透到数据库，这就是缓存穿透。

请求的数据在缓存大量不命中，导致请求走数据库。

缓存穿透一般都是这几种情况产生的：

- **业务不合理的设计**
- **业务/运维/开发失误的操作**，比如缓存和数据库的数据都被误删除了。
- **黑客非法请求攻击**，比如黑客故意捏造大量非法请求，以读取不存在的业务数据。

**如何避免缓存穿透呢？** 一般有三种方法。

-  如果是非法请求，我们在API入口，对参数进行校验，过滤非法值。
-  如果查询数据库为空，我们可以**给缓存设置个空值，或者默认值**。但是如有有写请求进来的话，需要更新缓存，以保证缓存一致性，同时，最后给缓存**设置适当的过期时间**。（业务上比较常用，简单有效）
-  使用布隆过滤器快速判断数据是否存在。即一个查询请求过来时，先通过**布隆过滤器**判断值是否存在，存在才继续往下查。

> 布隆过滤器原理：它由初始值为 0 的位图数组和 N 个哈希函数组成。一个对一个 key 进行 N 个 hash 算法获取 N 个值，在比特数组中将这 N 个值散列后设定为 1，然后查的时候如果特定的这几个位置都为 1，那么布隆过滤器判断该 key 可能存在。

#### **缓存雪崩**

**缓存雪崩：** 指缓存中数据大批量到过期时间，而查询数据量巨大，请求都直接访问数据库，引起数据库压力过大甚至 down 机。

**解决**：

- 缓存雪奔一般是由于**大量数据同时过期**造成的，对于这个原因，可通过均匀设置过期时间解决，即让过期时间相对离散一点。如采用一个较大固定值加一个较小的随机值，5 小时 + 0 到 1800 秒酱紫。
- Redis 故障宕机也可能引起缓存雪崩。这就需要构造 Redis 高可用集群啦。

对于“Redis 挂掉了，请求全部走数据库”这种情况，我们可以有以下的思路：

- 事发前：实现 Redis 的**高可用**（主从架构 + Sentinel 或者 Redis Cluster），尽量避免 Redis 挂掉这种情况发生。
- 事发中：万一 Redis 真的挂了，我们可以设置**本地缓存(ehcache)+限流(hystrix)**，尽量避免我们的数据库被干掉(起码能保证我们的服务还是能正常工作的)
- 事发后：Redis 持久化，重启后自动从磁盘上加载数据，**快速恢复缓存数据**。



#### 缓存击穿问题

**缓存击穿：**指**热点 key** 在某个时间点过期的时候，而恰好在这个时间点对这个 Key 有大量的并发请求过来，从而大量的请求打到 db。

缓存击穿看着有点像缓存雪崩，其实它两区别是，==**缓存雪崩是指数据库压力过大甚至 down 机，缓存击穿只是大量并发请求到了 DB 数据库层面**==。

解决方案就有两种：

- **1.使用互斥锁方案**。缓存失效时，不是立即去加载 db 数据，而是先使用某些带成功返回的原子操作命令，如(Redis 的 setnx）去操作，成功的时候，再去加载 db 数据库数据和设置缓存。
- **2. “永不过期”**，是指没有设置过期时间，但是热点数据快要过期时，异步线程去更新和设置过期时间。



#### 缓存与数据库双写一致

https://mp.weixin.qq.com/s/3Fmv7h5p2QDtLxc9n1dp5A

==必读==[2W字！详解20道Redis经典面试题！（珍藏版）](https://mp.weixin.qq.com/s/1wqbnpN8aeDBoy9NDh66vg)

- 缓存延时双删
- 删除缓存重试机制
- 读取biglog异步删除缓存

##### 延时双删

什么是延时双删呢？流程图如下：

![延时双删](https://cdn.jsdelivr.net/gh/YangZhiqiang98/ImageBed/20211101204233.png)

1. 先删除缓存
2. 再更新数据库
3. 休眠一会（比如1秒），再次删除缓存。

这个休眠一会，一般多久呢？都是1秒？

> 这个休眠时间 =  读业务逻辑数据的耗时 + 几百毫秒。为了确保读请求结束，写请求可以删除读请求可能带来的缓存脏数据。

这种方案还算可以，只有休眠那一会（比如就那1秒），可能有脏数据，一般业务也会接受的。但是如果**第二次删除缓存失败**呢？缓存和数据库的数据还是可能不一致，对吧？给 Key 设置一个自然的 expire 过期时间，让它自动过期怎样？那业务要接受过期时间内，数据的不一致咯？还是有其他更佳方案呢？

##### 删除缓存重试机制

因为延时双删可能会存在第二步的删除缓存失败，导致的数据不一致问题。可以使用这个方案优化：删除失败就多删除几次呀,保证删除缓存成功就可以了呀~ 所以可以引入删除缓存重试机制

![删除缓存重试流程](https://cdn.jsdelivr.net/gh/YangZhiqiang98/ImageBed/20211101204341.jpg)

1. 写请求更新数据库
2. 缓存因为某些原因，删除失败
3. 把删除失败的key放到消息队列
4. 消费消息队列的消息，获取要删除的key
5. 重试删除缓存操作

##### 读取binlog异步删除缓存

重试删除缓存机制还可以吧，就是会造成好多**业务代码入侵**。其实，还可以这样优化：通过数据库的 binlog 来异步淘汰 key。

![读取biglog异步删除缓存](https://cdn.jsdelivr.net/gh/YangZhiqiang98/ImageBed/20211101204426.jpg)

以 MySql 为例吧

- 可以使用阿里的 canal 将 binlog 日志采集发送到 MQ 队列里面
- 然后通过 ACK 机制确认处理这条更新消息，删除缓存，保证数据缓存一致性
